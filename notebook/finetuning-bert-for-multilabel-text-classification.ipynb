{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Fine Tune BERT for multilabel text classification"]},{"cell_type":"markdown","metadata":{},"source":["**loading datasets**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T21:04:23.526904Z","iopub.status.busy":"2023-12-27T21:04:23.526210Z","iopub.status.idle":"2023-12-27T21:04:35.450677Z","shell.execute_reply":"2023-12-27T21:04:35.449424Z","shell.execute_reply.started":"2023-12-27T21:04:23.526869Z"},"trusted":true},"outputs":[],"source":["!pip install -q transformers\n","!pip install -q transformers[torch]\n","!pip install -q accelerate --upgrade\n","!pip install --upgrade datasets "]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T21:04:36.909544Z","iopub.status.busy":"2023-12-27T21:04:36.909155Z","iopub.status.idle":"2023-12-27T21:04:40.473093Z","shell.execute_reply":"2023-12-27T21:04:40.472127Z","shell.execute_reply.started":"2023-12-27T21:04:36.909503Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\aashi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["from datasets import load_dataset\n","\n","dataset = load_dataset(\"sem_eval_2018_task_1\", \"subtask5.english\")"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T21:04:40.476962Z","iopub.status.busy":"2023-12-27T21:04:40.475910Z","iopub.status.idle":"2023-12-27T21:04:40.483923Z","shell.execute_reply":"2023-12-27T21:04:40.483043Z","shell.execute_reply.started":"2023-12-27T21:04:40.476930Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'ID': '2017-En-21441',\n"," 'Tweet': \"“Worry is a down payment on a problem you may never have'. \\xa0Joyce Meyer.  #motivation #leadership #worry\",\n"," 'anger': False,\n"," 'anticipation': True,\n"," 'disgust': False,\n"," 'fear': False,\n"," 'joy': False,\n"," 'love': False,\n"," 'optimism': True,\n"," 'pessimism': False,\n"," 'sadness': False,\n"," 'surprise': False,\n"," 'trust': True}"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["dataset['train'][0]"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T21:04:40.485248Z","iopub.status.busy":"2023-12-27T21:04:40.484988Z","iopub.status.idle":"2023-12-27T21:04:40.499715Z","shell.execute_reply":"2023-12-27T21:04:40.498766Z","shell.execute_reply.started":"2023-12-27T21:04:40.485224Z"},"trusted":true},"outputs":[{"data":{"text/plain":["dict_keys(['ID', 'Tweet', 'anger', 'anticipation', 'disgust', 'fear', 'joy', 'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust'])"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["dataset['train'].features.keys()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T21:04:40.501134Z","iopub.status.busy":"2023-12-27T21:04:40.500858Z","iopub.status.idle":"2023-12-27T21:04:40.511315Z","shell.execute_reply":"2023-12-27T21:04:40.510379Z","shell.execute_reply.started":"2023-12-27T21:04:40.501108Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['anger',\n"," 'anticipation',\n"," 'disgust',\n"," 'fear',\n"," 'joy',\n"," 'love',\n"," 'optimism',\n"," 'pessimism',\n"," 'sadness',\n"," 'surprise',\n"," 'trust']"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["labels = [label for label in dataset['train'].features.keys() if label not in ['ID', 'Tweet']]\n","id2label = {idx:label for idx, label in enumerate(labels)}\n","label2id = {label:idx for idx, label in enumerate(labels)}\n","labels"]},{"cell_type":"markdown","metadata":{},"source":["**preprocess data**"]},{"cell_type":"code","execution_count":6,"metadata":{"_kg_hide-output":false,"execution":{"iopub.execute_input":"2023-12-27T21:04:40.512827Z","iopub.status.busy":"2023-12-27T21:04:40.512553Z","iopub.status.idle":"2023-12-27T21:04:40.532409Z","shell.execute_reply":"2023-12-27T21:04:40.531539Z","shell.execute_reply.started":"2023-12-27T21:04:40.512802Z"},"trusted":true},"outputs":[{"data":{"text/plain":["\"“Worry is a down payment on a problem you may never have'. \\xa0Joyce Meyer.  #motivation #leadership #worry\""]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["dataset['train']['Tweet'][0]"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T21:04:40.543382Z","iopub.status.busy":"2023-12-27T21:04:40.543091Z","iopub.status.idle":"2023-12-27T21:04:42.939336Z","shell.execute_reply":"2023-12-27T21:04:42.938530Z","shell.execute_reply.started":"2023-12-27T21:04:40.543356Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoTokenizer\n","import numpy as np\n","tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\", problem_type='multi_label_classification')\n","\n","def preprocess_data(examples):\n","    #take batch of texts\n","    text = examples[\"Tweet\"]\n","    #encode them\n","    encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=128)\n","    #add labels\n","    labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n","    #create numpy array of shape (batch size, num_labels)\n","    labels_matrix = np.zeros((len(text), len(labels)))\n","    #fill numpy array\n","    for idx, label in enumerate(labels):\n","        labels_matrix[:, idx] = labels_batch[label]\n","        \n","    encoding[\"labels\"] = labels_matrix.tolist()\n","    \n","    return encoding"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T21:04:42.942123Z","iopub.status.busy":"2023-12-27T21:04:42.941648Z","iopub.status.idle":"2023-12-27T21:04:44.569840Z","shell.execute_reply":"2023-12-27T21:04:44.568862Z","shell.execute_reply.started":"2023-12-27T21:04:42.942094Z"},"trusted":true},"outputs":[],"source":["encoded_dataset = dataset.map(preprocess_data, batched=True, remove_columns=dataset['train'].column_names)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T21:04:49.065870Z","iopub.status.busy":"2023-12-27T21:04:49.064924Z","iopub.status.idle":"2023-12-27T21:04:49.664592Z","shell.execute_reply":"2023-12-27T21:04:49.663587Z","shell.execute_reply.started":"2023-12-27T21:04:49.065833Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[101,\n"," 1523,\n"," 4737,\n"," 2003,\n"," 1037,\n"," 2091,\n"," 7909,\n"," 2006,\n"," 1037,\n"," 3291,\n"," 2017,\n"," 2089,\n"," 2196,\n"," 2031,\n"," 1005,\n"," 1012,\n"," 11830,\n"," 11527,\n"," 1012,\n"," 1001,\n"," 14354,\n"," 1001,\n"," 4105,\n"," 1001,\n"," 4737,\n"," 102,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["encoded_dataset['train']['input_ids'][0]"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T21:05:38.542214Z","iopub.status.busy":"2023-12-27T21:05:38.541155Z","iopub.status.idle":"2023-12-27T21:05:38.549281Z","shell.execute_reply":"2023-12-27T21:05:38.548141Z","shell.execute_reply.started":"2023-12-27T21:05:38.542163Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n"]}],"source":["example = encoded_dataset['train'][0]\n","print(example.keys())"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T21:05:41.697360Z","iopub.status.busy":"2023-12-27T21:05:41.696449Z","iopub.status.idle":"2023-12-27T21:05:44.386600Z","shell.execute_reply":"2023-12-27T21:05:44.385259Z","shell.execute_reply.started":"2023-12-27T21:05:41.697315Z"},"trusted":true},"outputs":[{"data":{"text/plain":["\"[CLS] “ worry is a down payment on a problem you may never have '. joyce meyer. # motivation # leadership # worry [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\""]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.decode(example['input_ids'])"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T21:05:44.390705Z","iopub.status.busy":"2023-12-27T21:05:44.389281Z","iopub.status.idle":"2023-12-27T21:05:44.398987Z","shell.execute_reply":"2023-12-27T21:05:44.397813Z","shell.execute_reply.started":"2023-12-27T21:05:44.390646Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["example['labels']"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T21:05:44.402106Z","iopub.status.busy":"2023-12-27T21:05:44.401158Z","iopub.status.idle":"2023-12-27T21:05:44.417452Z","shell.execute_reply":"2023-12-27T21:05:44.416113Z","shell.execute_reply.started":"2023-12-27T21:05:44.402057Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['anticipation', 'optimism', 'trust']"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["[id2label[idx] for idx, label in enumerate(example['labels']) if label == 1.0]"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T21:05:44.421335Z","iopub.status.busy":"2023-12-27T21:05:44.420519Z","iopub.status.idle":"2023-12-27T21:05:44.429086Z","shell.execute_reply":"2023-12-27T21:05:44.427867Z","shell.execute_reply.started":"2023-12-27T21:05:44.421272Z"},"trusted":true},"outputs":[],"source":["#set the format of the data to PyTorch tensors to make a standard PyTorch datasets.\n","encoded_dataset.set_format(\"torch\")"]},{"cell_type":"markdown","metadata":{},"source":["**Define a model**"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T21:05:45.573923Z","iopub.status.busy":"2023-12-27T21:05:45.573095Z","iopub.status.idle":"2023-12-27T21:05:46.081290Z","shell.execute_reply":"2023-12-27T21:05:46.080274Z","shell.execute_reply.started":"2023-12-27T21:05:45.573885Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import AutoModelForSequenceClassification\n","\n","model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", \n","                                                           problem_type=\"multi_label_classification\", \n","                                                           num_labels=len(labels),\n","                                                           id2label=id2label,\n","                                                           label2id=label2id)"]},{"cell_type":"markdown","metadata":{},"source":["**train the model**"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T21:05:46.426050Z","iopub.status.busy":"2023-12-27T21:05:46.425177Z","iopub.status.idle":"2023-12-27T21:05:46.430238Z","shell.execute_reply":"2023-12-27T21:05:46.429068Z","shell.execute_reply.started":"2023-12-27T21:05:46.426015Z"},"trusted":true},"outputs":[],"source":["batch_size = 8\n","metric_name = \"f1\""]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T21:05:51.256263Z","iopub.status.busy":"2023-12-27T21:05:51.255428Z","iopub.status.idle":"2023-12-27T21:05:51.582034Z","shell.execute_reply":"2023-12-27T21:05:51.581008Z","shell.execute_reply.started":"2023-12-27T21:05:51.256226Z"},"trusted":true},"outputs":[],"source":["from transformers import Trainer, TrainingArguments\n","\n","args = TrainingArguments(\n","    f\"bert-finetuned-sem_eval-english\",\n","    evaluation_strategy = \"epoch\",\n","    save_strategy = \"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    num_train_epochs=5,\n","    weight_decay=0.01,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=metric_name,\n","    save_total_limit=1,\n","    #push_to_hub=True,\n",")"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T21:05:52.195768Z","iopub.status.busy":"2023-12-27T21:05:52.195084Z","iopub.status.idle":"2023-12-27T21:05:52.205129Z","shell.execute_reply":"2023-12-27T21:05:52.204101Z","shell.execute_reply.started":"2023-12-27T21:05:52.195731Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n","from transformers import EvalPrediction\n","import torch\n","    \n","def multi_label_metrics(predictions, labels, threshold=0.5):\n","    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n","    sigmoid = torch.nn.Sigmoid()\n","    probs = sigmoid(torch.Tensor(predictions))\n","    # next, use threshold to turn them into integer predictions\n","    y_pred = np.zeros(probs.shape)\n","    y_pred[np.where(probs >= threshold)] = 1\n","    # finally, compute metrics\n","    y_true = labels\n","    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n","    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n","    accuracy = accuracy_score(y_true, y_pred)\n","    # return as dictionary\n","    metrics = {'f1': f1_micro_average,\n","               'roc_auc': roc_auc,\n","               'accuracy': accuracy}\n","    return metrics\n","\n","def compute_metrics(p: EvalPrediction):\n","    preds = p.predictions[0] if isinstance(p.predictions, \n","            tuple) else p.predictions\n","    result = multi_label_metrics(\n","        predictions=preds, \n","        labels=p.label_ids)\n","    return result"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T21:06:10.062292Z","iopub.status.busy":"2023-12-27T21:06:10.061630Z","iopub.status.idle":"2023-12-27T21:06:10.069811Z","shell.execute_reply":"2023-12-27T21:06:10.068787Z","shell.execute_reply.started":"2023-12-27T21:06:10.062257Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.])"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["encoded_dataset['train'][0]['labels']"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T21:06:40.551238Z","iopub.status.busy":"2023-12-27T21:06:40.550536Z","iopub.status.idle":"2023-12-27T21:06:40.578116Z","shell.execute_reply":"2023-12-27T21:06:40.577115Z","shell.execute_reply.started":"2023-12-27T21:06:40.551185Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([  101,  1523,  4737,  2003,  1037,  2091,  7909,  2006,  1037,  3291,\n","         2017,  2089,  2196,  2031,  1005,  1012, 11830, 11527,  1012,  1001,\n","        14354,  1001,  4105,  1001,  4737,   102,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0])"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["encoded_dataset['train']['input_ids'][0]"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T21:07:04.453361Z","iopub.status.busy":"2023-12-27T21:07:04.452956Z","iopub.status.idle":"2023-12-27T21:07:05.057555Z","shell.execute_reply":"2023-12-27T21:07:05.056562Z","shell.execute_reply.started":"2023-12-27T21:07:04.453320Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"]},{"data":{"text/plain":["SequenceClassifierOutput(loss=tensor(0.8145, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), logits=tensor([[ 0.1884, -0.4015, -0.0330, -0.0193,  0.4628, -0.2130, -0.1709,  0.2449,\n","          0.5960,  0.1553, -0.4384]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["#forward pass\n","outputs = model(input_ids=encoded_dataset['train']['input_ids'][0].unsqueeze(0), labels=encoded_dataset['train'][0]['labels'].unsqueeze(0))\n","outputs"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T21:07:20.098570Z","iopub.status.busy":"2023-12-27T21:07:20.097646Z","iopub.status.idle":"2023-12-27T21:07:25.418400Z","shell.execute_reply":"2023-12-27T21:07:25.417404Z","shell.execute_reply.started":"2023-12-27T21:07:20.098525Z"},"trusted":true},"outputs":[],"source":["trainer = Trainer(\n","    model,\n","    args,\n","    train_dataset=encoded_dataset[\"train\"],\n","    eval_dataset=encoded_dataset[\"validation\"],\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["eval_results_per_epoch = []\n","def save_eval_results(eval_results, epoch):\n","    result_to_save = {\n","        \"epoch\": epoch,\n","        \"eval_loss\": eval_results[\"eval_loss\"],\n","        \"eval_f1\": eval_results[\"eval_f1\"],\n","        \"eval_roc_auc\": eval_results[\"eval_roc_auc\"],\n","        \"eval_accuracy\": eval_results[\"eval_accuracy\"],\n","    }\n","    eval_results_per_epoch.append(result_to_save)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T21:07:35.839106Z","iopub.status.busy":"2023-12-27T21:07:35.838711Z","iopub.status.idle":"2023-12-27T21:18:25.321347Z","shell.execute_reply":"2023-12-27T21:18:25.320116Z","shell.execute_reply.started":"2023-12-27T21:07:35.839074Z"},"trusted":true},"outputs":[{"ename":"AttributeError","evalue":"'AcceleratorState' object has no attribute 'distributed_type'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn[60], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\aashi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m   1536\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1537\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1538\u001b[0m )\n\u001b[1;32m-> 1539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1544\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\aashi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\trainer.py:1553\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1551\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrently training with a batch size of: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;66;03m# Data loader and number of training steps\u001b[39;00m\n\u001b[1;32m-> 1553\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_train_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1555\u001b[0m \u001b[38;5;66;03m# Setting up training control variables:\u001b[39;00m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;66;03m# number of training epochs: num_train_epochs\u001b[39;00m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# number of training steps per epoch: num_update_steps_per_epoch\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# total number of training steps to execute: max_steps\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m total_train_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size \u001b[38;5;241m*\u001b[39m args\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps \u001b[38;5;241m*\u001b[39m args\u001b[38;5;241m.\u001b[39mworld_size\n","File \u001b[1;32mc:\\Users\\aashi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\trainer.py:854\u001b[0m, in \u001b[0;36mTrainer.get_train_dataloader\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    851\u001b[0m     dataloader_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop_last\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdataloader_drop_last\n\u001b[0;32m    852\u001b[0m     dataloader_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworker_init_fn\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m seed_worker\n\u001b[1;32m--> 854\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdataloader_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\aashi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\accelerate\\accelerator.py:1173\u001b[0m, in \u001b[0;36mAccelerator.prepare\u001b[1;34m(self, device_placement, *args)\u001b[0m\n\u001b[0;32m   1162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1163\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(obj, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule)\n\u001b[0;32m   1164\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_device_map(obj)\n\u001b[0;32m   1165\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mNO\n\u001b[0;32m   1166\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mACCELERATE_BYPASS_DEVICE_MAP\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfalse\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1167\u001b[0m     ):\n\u001b[0;32m   1168\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1169\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt train a model that has been loaded with `device_map=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m` in any distributed mode.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1170\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please rerun your script specifying `--num_processes=1` or by launching with `python \u001b[39m\u001b[38;5;124m{{\u001b[39m\u001b[38;5;124mmyscript.py}}`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1171\u001b[0m         )\n\u001b[1;32m-> 1173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributed_type\u001b[49m \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[0;32m   1174\u001b[0m     model_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1175\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m args:\n","File \u001b[1;32mc:\\Users\\aashi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\accelerate\\accelerator.py:485\u001b[0m, in \u001b[0;36mAccelerator.distributed_type\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdistributed_type\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributed_type\u001b[49m\n","\u001b[1;31mAttributeError\u001b[0m: 'AcceleratorState' object has no attribute 'distributed_type'"]}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T21:26:48.869888Z","iopub.status.busy":"2023-12-27T21:26:48.869448Z","iopub.status.idle":"2023-12-27T21:26:52.915546Z","shell.execute_reply":"2023-12-27T21:26:52.914037Z","shell.execute_reply.started":"2023-12-27T21:26:48.869857Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 111/111 [00:07<00:00, 15.73it/s]\n"]}],"source":["#evaluate\n","evaluation_results = trainer.evaluate()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["**Inference**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T21:26:57.667344Z","iopub.status.busy":"2023-12-27T21:26:57.666931Z","iopub.status.idle":"2023-12-27T21:26:57.690889Z","shell.execute_reply":"2023-12-27T21:26:57.689881Z","shell.execute_reply.started":"2023-12-27T21:26:57.667299Z"},"trusted":true},"outputs":[],"source":["text = \"I'm happy I can finally train a model for multi-label classification\"\n","\n","encoding = tokenizer(text, return_tensors=\"pt\")\n","encoding = {k: v.to(trainer.model.device) for k,v in encoding.items()}\n","\n","outputs = trainer.model(**encoding)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T21:26:58.507967Z","iopub.status.busy":"2023-12-27T21:26:58.507581Z","iopub.status.idle":"2023-12-27T21:26:58.516659Z","shell.execute_reply":"2023-12-27T21:26:58.515367Z","shell.execute_reply.started":"2023-12-27T21:26:58.507935Z"},"trusted":true},"outputs":[{"data":{"text/plain":["torch.Size([1, 11])"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["logits = outputs.logits\n","logits.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T21:26:58.760027Z","iopub.status.busy":"2023-12-27T21:26:58.759619Z","iopub.status.idle":"2023-12-27T21:26:58.769251Z","shell.execute_reply":"2023-12-27T21:26:58.768204Z","shell.execute_reply.started":"2023-12-27T21:26:58.759997Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['joy', 'optimism']\n"]}],"source":["# apply sigmoid + threshold\n","sigmoid = torch.nn.Sigmoid()\n","probs = sigmoid(logits.squeeze().cpu())\n","predictions = np.zeros(probs.shape)\n","predictions[np.where(probs >= 0.5)] = 1\n","# turn predicted id's into actual label names\n","predicted_labels = [id2label[idx] for idx, label in enumerate(predictions) if label == 1.0]\n","print(predicted_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.save_pretrained(\"bert-finetuned-sem_eval-english-final\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30627,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"}},"nbformat":4,"nbformat_minor":4}
